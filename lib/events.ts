/*
 * Copyright © 2021 Atomist, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import {
	AttachmentTarget,
	Contextual,
	EventHandler,
	github,
	repository,
	secret,
	slack,
	status,
	subscription,
} from "@atomist/skill";
import * as fs from "fs-extra";
import * as _ from "lodash";
import * as path from "path";

import { Configuration } from "./configuration";
import {
	aggregate,
	diffAggregates,
	DiffQuality,
	format,
	formatAggregateDiffs,
	formatAggregates,
	formatDiffs,
	qualifyDiff,
	TrivyReport,
} from "./report";
import {
	DockerRegistryQuery,
	DockerRegistryQueryVariables,
	OnDockerRegistryImageSubscription,
} from "./typings/types";

/**
 * Event handler entry point for onDockerRegistryImage events
 */
export const onDockerRegistryImage: EventHandler<
	OnDockerRegistryImageSubscription,
	Configuration
> = async ctx => {
	const image = ctx.data.DockerRegistryImage?.[0]?.imageName;
	const commit = ctx.data.DockerRegistryImage?.[0]?.commit;
	const cfg = ctx.configuration?.parameters || {};

	const credential = await ctx.credential.resolve(
		secret.gitHubAppToken({
			owner: commit.repo.owner,
			repo: commit.repo.name,
			apiUrl: commit.repo.org.provider.apiUrl,
		}),
	);

	const project = await ctx.project.load(
		repository.gitHub({
			owner: commit.repo.owner,
			repo: commit.repo.name,
			credential,
			sha: commit.sha,
		}),
		process.env.ATOMIST_HOME,
	);

	// TODO CD move this back into skill
	const resourceProviderId =
		ctx.configuration.resourceProviders.docker
			?.selectedResourceProviders?.[0]?.id;

	const env = { ...process.env };
	if (resourceProviderId) {
		const resourceProviderResult = await ctx.graphql.query<
			DockerRegistryQuery,
			DockerRegistryQueryVariables
		>("dockerRegistry.graphql", { id: resourceProviderId });
		if (resourceProviderResult.DockerRegistry?.[0]) {
			const resourceProvider = resourceProviderResult.DockerRegistry?.[0];
			if (resourceProvider) {
				switch (resourceProvider.__typename) {
					case "DockerHubRegistryProvider":
					case "JFrogDockerRegistryProvider":
						env.TRIVY_USERNAME =
							resourceProvider.credential.owner.login;
						env.TRIVY_PASSWORD = (resourceProvider.credential as any).secret;
						break;
					case "GoogleContainerRegistryProvider":
						env.TRIVY_USERNAME = "";
						env.GOOGLE_APPLICATION_CREDENTIALS = project.path(
							"google_creds.json",
						);
						await fs.writeFile(
							project.path("google_creds.json"),
							(resourceProvider.credential as any).secret,
						);
						break;
				}
			}
		}
	}

	const outputFile = path.join(project.path("output.json"));

	const check = await github.createCheck(ctx, project.id, {
		name: "docker-vulnerability-scanner-skill",
		title: "trivy",
		sha: commit.sha,
		body: `Scanning docker image \`${image}\``,
	});

	const cmd = "trivy";
	const args = [
		"--cache-dir",
		path.join(process.env.ATOMIST_HOME, ".cache"),
		"image",
		"--exit-code",
		"1",
	];

	if (cfg.severity?.length > 0) {
		args.push("--severity", cfg.severity.join(","));
	}
	if (cfg.ignoreUnfixed === true) {
		args.push("--ignore-unfixed");
	}
	if (cfg.ignoreCves?.length > 0) {
		const ignoreFile = project.path(".ignore");
		await fs.writeFile(ignoreFile, cfg.ignoreCves.join("\n"));
		args.push("--ignorefile", ignoreFile);
	}
	args.push("--format", "json");
	args.push("--output", outputFile, "--no-progress");
	args.push(image);

	const result = await project.spawn(cmd, args, { env });
	const report = (await fs.readFile(outputFile)).toString();

	await ctx.storage.store(
		cacheKey(
			commit.repo.owner,
			commit.repo.name,
			commit.sha,
			ctx.configuration.name,
			ctx,
		),
		outputFile,
	);

	if (result.status !== 0) {
		const aggregates = aggregate(report);
		const formattedAggregates = formatAggregates(aggregates);

		let diff = "";
		let beforeReport;
		try {
			const beforeOutputFile = await ctx.storage.retrieve(
				cacheKey(
					commit.repo.owner,
					commit.repo.name,
					"baseline",
					ctx.configuration.name,
					ctx,
				),
			);
			beforeReport = (await fs.readFile(beforeOutputFile)).toString();
			diff = formatDiffs(
				JSON.parse(beforeReport),
				JSON.parse(report),
				"set baseline",
			);
		} catch (e) {
			// Intentionally left empty
		}
		if (!beforeReport) {
			try {
				const beforeOutputFile = await ctx.storage.retrieve(
					cacheKey(
						commit.repo.owner,
						commit.repo.name,
						commit.pushes?.[0]?.before.sha,
						ctx.configuration.name,
						ctx,
					),
				);
				beforeReport = (await fs.readFile(beforeOutputFile)).toString();
				diff = formatDiffs(
					JSON.parse(beforeReport),
					JSON.parse(report),
					`previous commit \`${commit.pushes?.[0]?.before.sha.slice(
						0,
						7,
					)}\``,
				);
			} catch (e) {
				// Intentionally left empty
			}
		}

		let conclusion: any =
			cfg.failOn === "on_changed_vulnerabilities"
				? "neutral"
				: "action_required";

		// If no before aggregates are available use the current as baseline
		const beforeAggregates = beforeReport
			? aggregate(beforeReport)
			: aggregates;

		const qualify = qualifyDiff(
			diffAggregates(beforeAggregates, aggregates),
		);

		let color;
		if (qualify === DiffQuality.Improved) {
			conclusion =
				cfg.failOn === "on_changed_vulnerabilities"
					? "success"
					: conclusion;
			color = "#D7B958";
		} else if (qualify === DiffQuality.Decline) {
			conclusion =
				cfg.failOn === "on_changed_vulnerabilities"
					? "action_required"
					: conclusion;
			color = "#BC3D33";
		} else if (qualify === DiffQuality.NoChange) {
			conclusion =
				cfg.failOn === "on_changed_vulnerabilities"
					? "neutral"
					: conclusion;
			color = "#B5B5B5";
		}

		const formattedDiffs = formatAggregateDiffs(
			beforeAggregates,
			aggregates,
		);

		const msg: slack.SlackMessage = {
			attachments: [
				{
					text: `Detected ${formattedDiffs.msg} ${
						formattedDiffs.count === 1
							? "vulnerability"
							: "vulnerabilities"
					} in image \`${image}\`
${diff.length > 0 ? `\n${slack.githubToSlack(diff)}\n` : ""}`,
					fallback: "Docker Image Vulnerabilities",
					color,
					footer: `${slack.url(
						ctx.audit.url,
						"Docker Image Vulnerabilities",
					)} · ${slack.url(check.data.html_url, "Details")}`,
					mrkdwn_in: ["text"],
					actions: [
						slack.buttonForCommand(
							{ text: "Set baseline" },
							"setBaseline",
							{
								owner: commit.repo.owner,
								repo: commit.repo.name,
								sha: commit.pushes?.[0]?.before.sha,
								cfg: ctx.configuration.name,
							},
						),
					],
				},
			],
		};

		await ctx.message.attach(
			msg.attachments[0],
			AttachmentTarget.Push,
			`${commit.sha}#${commit.pushes?.[0]?.branch}`,
			"docker-vulnerabilities",
			Date.now(),
		);

		await check.update({
			conclusion,
			body: `\`trivy\` found ${formattedAggregates.msg} security ${
				formattedAggregates.count === 1
					? "vulnerability"
					: "vulnerabilities"
			}.

\`\`\`
$ trivy ${args.join(" ")}
\`\`\`

${diff.length > 0 ? `---\n\n${diff}` : ""}
${format(report)}`,
		});

		return status.failure(`Vulnerabilities found on \`${image}\``);
	} else {
		await check.update({
			conclusion: "success",
			body: `\`trivy\` found no security vulnerabilities

\`\`\`
$ trivy ${args.join(" ")}
\`\`\``,
		});
		return status.success(`No vulnerabilities found on \`${image}\``);
	}
};

export function cacheKey(
	owner: string,
	repo: string,
	sha: string,
	configurationName: string,
	ctx: Contextual<any, any>,
): string {
	return `docker-vulnerabilities/${ctx.workspaceId}/${ctx.skill.namespace}/${
		ctx.skill.name
	}/${configurationName
		.replace(/[^a-zA-Z0-9-_]/g, "")
		.toLowerCase()}/${owner.replace(/[^a-zA-Z0-9-_]/g, "")}/${repo.replace(
		/[^a-zA-Z0-9-_]/g,
		"",
	)}/${sha}.json`;
}

export const onDockerImage: EventHandler<
	subscription.datalog.OnDockerImage,
	Configuration
> = async ctx => {
	const image = ctx.data.image.image;
	const digest = ctx.data.image.digest;
	const commit = ctx.data.commit;
	const registry = ctx.data.registry;
	const cfg = ctx.configuration?.parameters || {};

	const credential = {
		token: ctx.data.commit.repo.org.installationToken,
		permissions: {},
	};

	const project = await ctx.project.load(
		repository.gitHub({
			owner: commit.repo.org.name,
			repo: commit.repo.name,
			credential,
			sha: commit.sha,
		}),
		process.env.ATOMIST_HOME,
	);

	const env = { ...process.env };
	if (registry) {
		switch (registry.type.ident) {
			case "docker.registry.type/GCR":
				env.TRIVY_USERNAME = "";
				env.GOOGLE_APPLICATION_CREDENTIALS = project.path(
					"google_creds.json",
				);
				await fs.writeFile(
					project.path("google_creds.json"),
					registry.secret,
				);
				break;
			default:
				env.TRIVY_USERNAME = registry.username;
				env.TRIVY_PASSWORD = registry.secret;
				break;
		}
	}

	const outputFile = path.join(project.path("output.json"));

	const cmd = "trivy";
	const args = [
		"--cache-dir",
		path.join(process.env.ATOMIST_HOME, ".cache"),
		"image",
		"--exit-code",
		"1",
	];

	if (cfg.severity?.length > 0) {
		args.push("--severity", cfg.severity.join(","));
	}
	if (cfg.ignoreUnfixed === true) {
		args.push("--ignore-unfixed");
	}
	if (cfg.ignoreCves?.length > 0) {
		const ignoreFile = project.path(".ignore");
		await fs.writeFile(ignoreFile, cfg.ignoreCves.join("\n"));
		args.push("--ignorefile", ignoreFile);
	}
	args.push("--format", "json");
	args.push("--output", outputFile, "--no-progress");
	args.push(image);

	const result = await project.spawn(cmd, args, { env });

	if (result.status === 0) {
		return status.success(`No vulnerabilities found on \`${image}\``);
	} else {
		const report: TrivyReport = JSON.parse(
			(await fs.readFile(outputFile)).toString(),
		);

		const vuls = _.values(
			_.groupBy(
				_.flattenDeep(
					report
						.filter(r => r.Vulnerabilities)
						.map(r => r.Vulnerabilities),
				),
				"VulnerabilityID",
			),
		);
		const vulsChunks = _.chunk(vuls, 25);

		for (const vulChunk of vulsChunks) {
			const entities = [
				..._.flatten(
					vulChunk.map(vu =>
						vu
							.filter(v => v.InstalledVersion)
							.map(v => ({
								"schema/entity-type":
									":docker.analysis/package",
								"schema/entity": `$package-${v.VulnerabilityID}-${v.PkgName}`,
								"docker.analysis.package/name": v.PkgName,
								"docker.analysis.package/version":
									v.InstalledVersion,
							})),
					),
				),
				..._.flatten(
					vulChunk.map(vu =>
						vu
							.filter(v => v.FixedVersion)
							.map(v => ({
								"schema/entity-type":
									":docker.analysis/package",
								"schema/entity": `$package-fix-${v.VulnerabilityID}-${v.PkgName}`,
								"docker.analysis.package/name": v.PkgName,
								"docker.analysis.package/version":
									v.FixedVersion,
							})),
					),
				),
				...vulChunk.map(vu => {
					const v = vu[0];
					const cve = {
						"schema/entity-type": ":vulnerability/cve",
						"schema/entity": `$vulnerability-${v.VulnerabilityID}`,
						"vulnerability.cve/source-id": v.VulnerabilityID,
						"vulnerability.cve/severity": `:vulnerability.cve.severity/${mapSeverity(
							v.Severity,
						)}`,
						"vulnerability.cve/fix-available":
							v.FixedVersion !== undefined,
					};
					const affected = vu
						.filter(vup => vup.InstalledVersion)
						.map(
							vup =>
								`$package-${v.VulnerabilityID}-${vup.PkgName}`,
						);
					if (affected.length > 0) {
						cve["docker.analysis/affected"] = affected;
					}
					const fixed = vu
						.filter(vup => vup.FixedVersion)
						.map(
							vup =>
								`$package-fix-${v.VulnerabilityID}-${vup.PkgName}`,
						);
					if (fixed.length > 0) {
						cve["docker.analysis/fixed"] = fixed;
					}
					if (v.Description) {
						cve["vulnerability.cve/description"] = v.Description;
					}
					if (v.Title) {
						cve["vulnerability.cve/title"] = v.Title;
					}
					if (v.CVSS?.nvd?.V2Score !== undefined) {
						cve[
							"vulnerability.cve/cvss-score"
						] = v.CVSS?.nvd?.V2Score?.toString();
					}
					return cve;
				}),
				{
					"schema/entity-type": ":docker/image",
					"schema/entity": "$image",
					"docker.image/digest": digest,
					"docker.analysis/vulnerabilities": {
						add: vulChunk.map(
							v => `$vulnerability-${v[0].VulnerabilityID}`,
						),
					},
					"docker.analysis/affected": {
						add: _.flatten(
							vulChunk.map(v =>
								v
									.filter(v => v.InstalledVersion)
									.map(
										vup =>
											`$package-${vup.VulnerabilityID}-${vup.PkgName}`,
									),
							),
						),
					},
					"docker.analysis/fixed": {
						add: _.flatten(
							vulChunk.map(v =>
								v
									.filter(v => v.FixedVersion)
									.map(
										vup =>
											`$package-fix-${vup.VulnerabilityID}-${vup.PkgName}`,
									),
							),
						),
					},
				},
			];
			await ctx.transact(entities);
		}

		const entities = [
			{
				"schema/entity-type": ":docker/image",
				"schema/entity": "$image",
				"docker.image/digest": digest,
			},
			{
				"schema/entity-type": ":analysis/discovery",
				"analysis.discovery/image": "$image",
				"analysis.discovery/status":
					":analysis.discovery.status/FINISHED_SUCCESS",
				"analysis.discovery/source": ":analysis.discovery.source/TRIVY",
			},
		];

		await ctx.transact(entities);

		return status.failure(`Vulnerabilities found on \`${image}\``);
	}
};

function mapSeverity(severity: string): string {
	switch (severity) {
		case "UNKNOWN":
			return "SEVERITY_UNSPECIFIED";
		default:
			return severity;
	}
}
