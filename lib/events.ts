/*
 * Copyright Â© 2021 Atomist, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import { EventHandler, repository, status, subscription } from "@atomist/skill";
import * as fs from "fs-extra";
import * as _ from "lodash";
import * as path from "path";

import { Configuration } from "./configuration";
import { readLayers } from "./layers";
import { TrivyReport } from "./report";

export const onDockerImage: EventHandler<
	subscription.datalog.OnDockerImage,
	Configuration
> = async ctx => {
	const image = ctx.data.image;
	const digest = ctx.data.image.digest;
	const commit = ctx.data.commit;
	const registry = ctx.data.registry;

	const credential = {
		token: ctx.data.commit.repo.org.installationToken,
		permissions: {},
	};

	const project = await ctx.project.load(
		repository.gitHub({
			owner: commit.repo.org.name,
			repo: commit.repo.name,
			credential,
			sha: commit.sha,
		}),
		process.env.ATOMIST_HOME,
	);

	const env = { ...process.env };
	if (registry) {
		switch (registry.type) {
			case subscription.datalog.DockerRegistryType.Gcr:
				env.TRIVY_USERNAME = "";
				env.GOOGLE_APPLICATION_CREDENTIALS = project.path(
					"google_creds.json",
				);
				await fs.writeFile(
					project.path("google_creds.json"),
					registry.secret,
				);
				break;
			default:
				env.TRIVY_USERNAME = registry.username;
				env.TRIVY_PASSWORD = registry.secret;
				break;
		}
	}

	const outputFile = path.join(project.path("output.json"));

	const cmd = "trivy";
	const args = [
		"--cache-dir",
		path.join(process.env.ATOMIST_HOME, ".cache"),
		"image",
		"--exit-code",
		"1",
	];

	args.push("--format", "json");
	args.push("--output", outputFile, "--no-progress");

	const imageName =
		registry.type !== subscription.datalog.DockerRegistryType.DockerHub
			? `${image.repository.host}/${image.repository.name}`
			: image.repository.name;
	args.push(`${imageName}@${image.digest}`);

	const result = await project.spawn(cmd, args, { env });

	if (result.status === 0) {
		return status.success(`No vulnerabilities found on \`${imageName}\``);
	} else {
		const report: TrivyReport = JSON.parse(
			(await fs.readFile(outputFile)).toString(),
		);

		const vuls = _.values(
			_.groupBy(
				_.flattenDeep(
					report
						.filter(r => r.Vulnerabilities)
						.map(r => r.Vulnerabilities),
				),
				"VulnerabilityID",
			),
		);

		await ctx.audit.log(
			`Vulnerabilities ${commit.sha}: ${_.flattenDeep(vuls || [])
				.map(v => `${v.VulnerabilityID} - ${v.Severity}`)
				.join(", ")}`,
		);

		const vulsChunks = _.chunk(vuls, 25);

		for (const vulChunk of vulsChunks) {
			const entities = [
				..._.map(
					_.groupBy(_.flatten(vulChunk), "Layer.Digest"),
					(v, k) => ({
						"schema/entity-type": ":docker.image/blob",
						"docker.image.blob/digest": k,
						"docker.image.blob/vulnerabilities": {
							add: v.map(
								vul => `$vulnerability-${vul.VulnerabilityID}`,
							),
						},
					}),
				),
				..._.flatten(
					vulChunk.map(vu =>
						vu
							.filter(v => v.InstalledVersion)
							.map(v => ({
								"schema/entity-type":
									":docker.analysis/package",
								"schema/entity": `$package-${v.VulnerabilityID}-${v.PkgName}`,
								"docker.analysis.package/name": v.PkgName,
								"docker.analysis.package/version":
									v.InstalledVersion,
							})),
					),
				),
				..._.flatten(
					vulChunk.map(vu =>
						vu
							.filter(v => v.FixedVersion)
							.map(v => ({
								"schema/entity-type":
									":docker.analysis/package",
								"schema/entity": `$package-fix-${v.VulnerabilityID}-${v.PkgName}`,
								"docker.analysis.package/name": v.PkgName,
								"docker.analysis.package/version":
									v.FixedVersion,
							})),
					),
				),
				...vulChunk.map(vu => {
					const v = vu[0];
					const cve = {
						"schema/entity-type": ":vulnerability/cve",
						"schema/entity": `$vulnerability-${v.VulnerabilityID}`,
						"vulnerability.cve/source-id": v.VulnerabilityID,
						"vulnerability.cve/severity": `:vulnerability.cve.severity/${mapSeverity(
							v.Severity,
						)}`,
						"vulnerability.cve/effective-severity": `:vulnerability.cve.severity/${mapSeverity(
							v.Severity,
						)}`,
						"vulnerability.cve/fix-available":
							v.FixedVersion !== undefined,
					};
					const affected = vu
						.filter(vup => vup.InstalledVersion)
						.map(
							vup =>
								`$package-${v.VulnerabilityID}-${vup.PkgName}`,
						);
					if (affected.length > 0) {
						cve["docker.analysis/affected"] = affected;
					}
					const fixed = vu
						.filter(vup => vup.FixedVersion)
						.map(
							vup =>
								`$package-fix-${v.VulnerabilityID}-${vup.PkgName}`,
						);
					if (fixed.length > 0) {
						cve["docker.analysis/fixed"] = fixed;
					}
					if (v.Description) {
						cve["vulnerability.cve/description"] = v.Description;
					}
					if (v.Title) {
						cve["vulnerability.cve/title"] = v.Title;
					}
					if (v.CVSS?.nvd?.V2Score !== undefined) {
						cve[
							"vulnerability.cve/cvss-score"
						] = v.CVSS?.nvd?.V2Score?.toString();
					}
					if (v.PublishedDate) {
						cve["vulnerability.cve/created"] = new Date(
							v.PublishedDate,
						);
					}
					if (v.LastModifiedDate) {
						cve["vulnerability.cve/last-updated"] = new Date(
							v.LastModifiedDate,
						);
					}
					return cve;
				}),
				{
					"schema/entity-type": ":docker/image",
					"schema/entity": "$image",
					"docker.image/digest": digest,
					"docker.analysis/vulnerabilities": {
						add: vulChunk.map(
							v => `$vulnerability-${v[0].VulnerabilityID}`,
						),
					},
					"docker.analysis/affected": {
						add: _.flatten(
							vulChunk.map(v =>
								v
									.filter(v => v.InstalledVersion)
									.map(
										vup =>
											`$package-${vup.VulnerabilityID}-${vup.PkgName}`,
									),
							),
						),
					},
					"docker.analysis/fixed": {
						add: _.flatten(
							vulChunk.map(v =>
								v
									.filter(v => v.FixedVersion)
									.map(
										vup =>
											`$package-fix-${vup.VulnerabilityID}-${vup.PkgName}`,
									),
							),
						),
					},
				},
			];
			await ctx.transact(entities);
		}

		const entities = [
			{
				"schema/entity-type": ":docker/image",
				"schema/entity": "$image",
				"docker.image/digest": digest,
			},
			{
				"schema/entity-type": ":analysis/discovery",
				"analysis.discovery/image": "$image",
				"analysis.discovery/status":
					":analysis.discovery.status/FINISHED_SUCCESS",
				"analysis.discovery/source": ":analysis.discovery.source/TRIVY",
			},
		];

		await ctx.transact(entities);

		return status.failure(
			`${vuls.length} ${
				vuls.length === 1 ? "vulnerability" : "vulnerabilities"
			} found on \`${imageName}\``,
		);
	}
};

export const onDockerFile: EventHandler<
	subscription.datalog.OnDockerFile,
	Configuration
> = async ctx => {
	const image = ctx.data.image;
	const file = ctx.data.file;

	const imageName =
		ctx.data.registry.type !==
		subscription.datalog.DockerRegistryType.DockerHub
			? `${image.repository.host}/${image.repository.name}`
			: image.repository.name;

	let layerResult;
	try {
		layerResult = await readLayers(ctx);
	} catch (e) {
		return status.success(
			`Failed to map Dockerfile to image layers for \`${imageName}\``,
		);
	}
	const parser = await import("docker-file-parser");
	let lines = _.orderBy([...file.lines], "number");

	const layers = layerResult.map(h => {
		let run = h.command;
		if (h.command.startsWith("/bin/sh -c ")) {
			run = `RUN ${h.command.slice("/bin/sh -c ".length)}`;
			h.command = run;
		}
		const parsed = parser.parse(run)[0];
		for (const line of lines) {
			if (line.instruction === parsed.name) {
				let match = false;
				// RUN
				if (line.argsString === parsed.args) {
					match = true;
				} else if (_.isEqual(line.argsArray, parsed.args)) {
					match = true;
				} else if (_.isEqual(line.argsMap, parsed.args)) {
					match = true;
				}
				if (match) {
					(h as any).line = line.number;
					lines = lines.filter(l => l !== line);
				}
			}
		}
		return h;
	});
	const baselayers = layers.filter(l => (l as any).line === undefined);

	const baseImageFrom = _.orderBy(file.lines, "number")
		.filter(p => p.instruction === "FROM")
		.slice(-1)[0];

	const result: Array<{
		digest: string;
		lineNumber: number;
		command: string;
	}> = _.orderBy(
		[
			...layers
				.filter((l: any) => l.line)
				.map((l: any) => ({
					digest: l.digest,
					lineNumber: l.line,
					command: l.command,
				})),
			...baselayers.map((l: any) => ({
				digest: l.digest,
				lineNumber: baseImageFrom.number,
				command: baseImageFrom.instruction,
			})),
		],
		"lineNumber",
	);

	const entities = [
		// docker.file
		{
			"schema/entity-type": ":docker/file",
			"schema/entity": "$file",
			"docker.file/sha": file.sha,
			"docker.file/path": file.path,
		},
		// docker.file/lines for each line we are able to map
		..._.uniqBy(result, "lineNumber").map(r => ({
			"schema/entity-type": ":docker.file/line",
			"schema/entity": `$line-${r.lineNumber}`,
			"docker.file.line/file": "$file",
			"docker.file.line/number": r.lineNumber,
		})),
		// docker.image/blob for each line we are able to map
		...result.map(r => ({
			"schema/entity-type": ":docker.image/blob",
			"docker.image.blob/digest": r.digest,
			"docker.image.blob/created-by": `$line-${r.lineNumber}`,
		})),
	];

	await ctx.transact(entities);

	return status.success(
		`Mapped Dockerfile to image layers for \`${imageName}\``,
	);
};

function mapSeverity(severity: string): string {
	switch (severity) {
		case "UNKNOWN":
			return "SEVERITY_UNSPECIFIED";
		default:
			return severity;
	}
}
